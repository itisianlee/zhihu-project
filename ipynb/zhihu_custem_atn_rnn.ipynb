{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from config import Config\n",
    "import utils3\n",
    "from layer import *\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import time\n",
    "import single_atn_rnn as sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = Config(words_num=60, des_words_num=60, batch_size=256, eval_batch_size=300, hidden_size=256, lr=0.01, \n",
    "                reg_rate=0.00001, epoch_num=20, save_per_step=500, eval_per_step=50, keep_prob=0.5, \n",
    "                atn_hidden_size=256, shuffle=True, summary_dir=\"./Log/\", ckpt_path=\"./models/\",\n",
    "                dataset_dir=\"./ieee_zhihu_cup/\", num_sentences=2)\n",
    "vocab = pickle.load(open('./ieee_zhihu_cup/vocab.dict' ,'r'))\n",
    "utils = utils3.Utils(config, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Zhihu_Classifier(object):\n",
    "    def __init__(self, config, sess):\n",
    "        self.config = config\n",
    "        self.batch_size = config.batch_size\n",
    "        self.eval_batch_size = config.eval_batch_size\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.lr = config.lr\n",
    "        self.epoch_num = config.epoch_num\n",
    "        self.reg_rate = config.reg_rate\n",
    "        self.words_num = config.words_num\n",
    "        self.des_words_num = config.des_words_num\n",
    "        self.save_per_step = config.save_per_step\n",
    "        self.eval_per_step = config.eval_per_step\n",
    "        self.ckpt_path = config.ckpt_path\n",
    "        self.keep_prob = config.keep_prob\n",
    "        self.summary_dir = config.summary_dir\n",
    "        self.atn_hidden_size = config.atn_hidden_size\n",
    "        self.shuffle = config.shuffle\n",
    "        self.max_score = 0.0\n",
    "        self.dataset_dir = config.dataset_dir\n",
    "        self.num_sentences = config.num_sentences\n",
    "        \n",
    "        self.embed_size = \n",
    "        self.sess = sess\n",
    "        self.istrain = True\n",
    "    \n",
    "    def train(self):\n",
    "        # 生成数据\n",
    "        batches = utils.generate_t_batch()\n",
    "        eval_batches = utils.generate_e_batch()\n",
    "        \n",
    "        model = sa.HierarchicalAttention(1999, self.lr, self.batch_size, 1000, 0.9, self.words_num*2, \n",
    "                                         self.num_sentences, 570783, self.embed_size, self.hidden_size, \n",
    "                                         self.istrain, multi_label_flag=True)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.predict_top_5 = tf.nn.top_k(model.logits, k=5)\n",
    "        counter = 0\n",
    "        for batch in batches:\n",
    "            counter = counter + 1\n",
    "#             print(counter)\n",
    "            x_batch, x_des, a, b, y_batch = zip(*batch)\n",
    "            x_batch = np.concatenate((x_batch, x_des), axis=1)\n",
    "            self.batch_length = len(x_batch)\n",
    "            self.input_x = x_batch\n",
    "            \n",
    "            feed_dict = {model.input_x: self.input_x, \n",
    "                         model.dropout_keep_prob: self.keep_prob,\n",
    "                         model.batch_length:[self.batch_length*self.num_sentences*self.hidden_size],\n",
    "                         model.sen_batch_length:[self.batch_length*self.hidden_size*2],\n",
    "                         model.input_y_multilabel:y_batch}\n",
    "            train_loss, _= self.sess.run([model.loss_val, model.train_op], feed_dict) \n",
    "            \n",
    "            if (counter % self.eval_per_step == 0):\n",
    "                print (\"Step:\",counter)\n",
    "                print (\"Train loss:\",train_loss)\n",
    "                x_eval_batch, x_des, a, b, y_eval_batch, real_labels = zip(*(eval_batches.next()))\n",
    "                x_eval_batch = np.concatenate((x_eval_batch, x_des), axis=1)\n",
    "                self.eval_input_x = x_eval_batch\n",
    "                self.do_eval(model, self.eval_input_x, y_eval_batch, real_labels)\n",
    "                \n",
    "            \n",
    "    # 在验证集上做验证，报告损失、精确度\n",
    "    def do_eval(self, model, evalX, evalY, real_labels):\n",
    "        self.eval_batch_length = len(evalX)\n",
    "        feed_dict = {model.input_x: evalX,\n",
    "                     model.input_y_multilabel:evalY,\n",
    "                     model.dropout_keep_prob: 1.0, \n",
    "                     model.batch_length:[self.eval_batch_length*self.num_sentences*self.hidden_size],\n",
    "                     model.sen_batch_length:[self.eval_batch_length*self.hidden_size*2],\n",
    "                    }\n",
    "        curr_eval_loss, predict_5 = self.sess.run([model.loss_val, self.predict_top_5], feed_dict)\n",
    "        print (\"Evaluation loss:\",curr_eval_loss)\n",
    "#                     print (\"real_labels:\",real_labels[:5])\n",
    "#                     print (\"predict:\",predict_5[1][:5])\n",
    "#                     print (\"predict:\",predict_5[0][:5])\n",
    "        predict_label_and_marked_label_list = []\n",
    "        for predict,label in zip(predict_5[1],real_labels):\n",
    "            predict_label_and_marked_label_list.append((list(predict),list(label)))\n",
    "        score = utils.eval(predict_label_and_marked_label_list)\n",
    "        print(\"score:\",score)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going to use multi label loss.\n",
      "('sigmoid_cross_entropy_with_logits.losses:', <tf.Tensor 'loss/logistic_loss:0' shape=(?, 1999) dtype=float32>)\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[570783,256]\n\t [[Node: OptimizeLoss/train/update_Embedding/mul_2 = Mul[T=DT_FLOAT, _class=[\"loc:@Embedding\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](OptimizeLoss/Embedding/Adam/read, OptimizeLoss/train/beta1)]]\n\t [[Node: OptimizeLoss/train/update/_40 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_42181_OptimizeLoss/train/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op u'OptimizeLoss/train/update_Embedding/mul_2', defined at:\n  File \"/home/jasperyang/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-5561f614d9bc>\", line 3, in <module>\n    classifier.train()\n  File \"<ipython-input-3-99079c8ef575>\", line 34, in train\n    self.istrain, multi_label_flag=True)\n  File \"single_atn_rnn.py\", line 67, in __init__\n    self.train_op = self.train()\n  File \"single_atn_rnn.py\", line 203, in train\n    learning_rate=learning_rate, optimizer=\"Adam\",clip_gradients=self.clip_gradients)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/optimizers.py\", line 293, in optimize_loss\n    name=\"train\")\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 456, in apply_gradients\n    update_ops.append(processor.update_op(self, grad))\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 102, in update_op\n    return optimizer._apply_sparse_duplicate_indices(g, self._v)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 654, in _apply_sparse_duplicate_indices\n    return self._apply_sparse(gradient_no_duplicate_indices, var)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/adam.py\", line 193, in _apply_sparse\n    lambda x, i, v: state_ops.scatter_add(  # pylint: disable=g-long-lambda\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/adam.py\", line 174, in _apply_sparse_shared\n    m_t = state_ops.assign(m, m * beta1_t,\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 694, in _run_op\n    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 838, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 1061, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1377, in _mul\n    result = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[570783,256]\n\t [[Node: OptimizeLoss/train/update_Embedding/mul_2 = Mul[T=DT_FLOAT, _class=[\"loc:@Embedding\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](OptimizeLoss/Embedding/Adam/read, OptimizeLoss/train/beta1)]]\n\t [[Node: OptimizeLoss/train/update/_40 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_42181_OptimizeLoss/train/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5561f614d9bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZhihu_Classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-99079c8ef575>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m                          \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msen_batch_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_length\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                          model.input_y_multilabel:y_batch}\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_per_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[570783,256]\n\t [[Node: OptimizeLoss/train/update_Embedding/mul_2 = Mul[T=DT_FLOAT, _class=[\"loc:@Embedding\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](OptimizeLoss/Embedding/Adam/read, OptimizeLoss/train/beta1)]]\n\t [[Node: OptimizeLoss/train/update/_40 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_42181_OptimizeLoss/train/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op u'OptimizeLoss/train/update_Embedding/mul_2', defined at:\n  File \"/home/jasperyang/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-5561f614d9bc>\", line 3, in <module>\n    classifier.train()\n  File \"<ipython-input-3-99079c8ef575>\", line 34, in train\n    self.istrain, multi_label_flag=True)\n  File \"single_atn_rnn.py\", line 67, in __init__\n    self.train_op = self.train()\n  File \"single_atn_rnn.py\", line 203, in train\n    learning_rate=learning_rate, optimizer=\"Adam\",clip_gradients=self.clip_gradients)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/optimizers.py\", line 293, in optimize_loss\n    name=\"train\")\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 456, in apply_gradients\n    update_ops.append(processor.update_op(self, grad))\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 102, in update_op\n    return optimizer._apply_sparse_duplicate_indices(g, self._v)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 654, in _apply_sparse_duplicate_indices\n    return self._apply_sparse(gradient_no_duplicate_indices, var)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/adam.py\", line 193, in _apply_sparse\n    lambda x, i, v: state_ops.scatter_add(  # pylint: disable=g-long-lambda\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/adam.py\", line 174, in _apply_sparse_shared\n    m_t = state_ops.assign(m, m * beta1_t,\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 694, in _run_op\n    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 838, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 1061, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1377, in _mul\n    result = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[570783,256]\n\t [[Node: OptimizeLoss/train/update_Embedding/mul_2 = Mul[T=DT_FLOAT, _class=[\"loc:@Embedding\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](OptimizeLoss/Embedding/Adam/read, OptimizeLoss/train/beta1)]]\n\t [[Node: OptimizeLoss/train/update/_40 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_42181_OptimizeLoss/train/update\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    classifier = Zhihu_Classifier(config, sess)\n",
    "    classifier.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batches = utils.generate_e_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a,b,c = zip(*(batches.next()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
