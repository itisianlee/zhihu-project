{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import utils5\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import time\n",
    "import zhihu_crnn as crnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_dict = pickle.load(open('./ieee_zhihu_cup/word_dict' ,'r'))\n",
    "char_dict = pickle.load(open('./ieee_zhihu_cup/char_dict' ,'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnn_seq_length = 60 \n",
    "rnn_seq_length = 60\n",
    "batch_size = 256\n",
    "eval_batch_size = 2000\n",
    "hidden_size = 256\n",
    "lr = 0.005\n",
    "reg_rate = 0.0001\n",
    "epoch_num = 20\n",
    "save_per_step = 1000\n",
    "eval_per_step = 500\n",
    "keep_prob = 0.5 \n",
    "atn_hidden_size = 512\n",
    "shuffle = True\n",
    "ckpt_path = './models/'\n",
    "num_sentences = 2\n",
    "filter_sizes = [2,3,4,5,6,7]\n",
    "num_filters = 256\n",
    "decay_steps = 2000 \n",
    "decay_rate = 0.90\n",
    "vocab_size = len(word_dict) \n",
    "char_size = len(char_dict) \n",
    "embed_size = 128 \n",
    "is_train = True\n",
    "\n",
    "summary_dir = './Log/'\n",
    "max_score = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utils = utils5.Utils(words_num=rnn_seq_length, chars_num=cnn_seq_length, batch_size=batch_size, \n",
    "                     eval_batch_size=eval_batch_size, dataset_dir='./ieee_zhihu_cup/', \n",
    "                     epoch_num=epoch_num, word_dict=word_dict, char_dict=char_dict, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(sess, utils):\n",
    "    # 生成数据\n",
    "    batches = utils.generate_t_batch()\n",
    "    eval_batches = utils.generate_e_batch()\n",
    "    model = crnn.CRNN_char_word(cnn_seq_length, rnn_seq_length, batch_size, eval_batch_size, hidden_size, \n",
    "                                lr, reg_rate, epoch_num, save_per_step, eval_per_step, keep_prob, \n",
    "                                atn_hidden_size, shuffle, ckpt_path, num_sentences, \n",
    "                                filter_sizes, num_filters, decay_steps, decay_rate, \n",
    "                                vocab_size, char_size, embed_size, is_train)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    summary_writer = tf.summary.FileWriter(summary_dir, graph=tf.get_default_graph())\n",
    "    \n",
    "    for batch in batches:\n",
    "        x_char, x_word_tit, x_word_des, x_word_len_tit, x_word_len_des, y = zip(*batch)\n",
    "        rnn_input = np.concatenate((x_word_tit, x_word_des), axis=1)\n",
    "        batch_length = len(x_char)\n",
    "\n",
    "        feed_dict = {model.cnn_input: x_char, \n",
    "                     model.rnn_input: rnn_input,\n",
    "                     model.output_keep_prob: keep_prob,\n",
    "                     model.batch_length:[batch_length],\n",
    "                     model.labels:y,\n",
    "                     model.tit_input_len:x_word_len_tit,\n",
    "                     model.des_input_len:x_word_len_des}\n",
    "        \n",
    "        train_loss, step, summary, _= sess.run([model.loss, model.global_step, model.merged, model.train_op], \n",
    "                                                feed_dict) \n",
    "        summary_writer.add_summary(summary, step)\n",
    "        if (step % eval_per_step == 0 and step > 10000):\n",
    "            path = model.saver.save(sess, \"models/conv-rnn-model\", global_step=step)\n",
    "            print(\"Saved model checkpoint to {}\".format(path))  \n",
    "            \n",
    "            print (\"Step:\",step)\n",
    "            print (\"Train loss:\",train_loss)\n",
    "            \n",
    "            score_list = []\n",
    "            eval_loss_list = []\n",
    "            for i in range(20):\n",
    "                x_char, x_word_tit, x_word_des, x_word_len_tit, x_word_len_des, y, real_labels = \\\n",
    "                zip(*(eval_batches.next()))\n",
    "                x_eval_batch = np.concatenate((x_word_tit, x_word_des), axis=1)\n",
    "                score, eval_loss = do_eval(utils, sess, model, x_char, x_eval_batch, \n",
    "                                           x_word_len_tit, x_word_len_des, y, real_labels)\n",
    "                score_list.append(score)\n",
    "                eval_loss_list.append(eval_loss)\n",
    "            print(\"avg eval loss:\", np.mean(eval_loss_list))\n",
    "            save_best_model(score_list, step)\n",
    "        # 每训练save_per_step次保存1次模型\n",
    "#         if (step % save_per_step == 0):\n",
    "#             path = model.saver.save(sess, \"models/conv-rnn-model\", global_step=step)\n",
    "#             print(\"Saved model checkpoint to {}\".format(path))     \n",
    "            \n",
    "# 在验证集上做验证，报告损失、精确度\n",
    "def do_eval(utils, sess, model, cnn_input, rnn_input,x_word_len_tit, x_word_len_des, y, real_labels):\n",
    "    predict_top_5 = tf.nn.top_k(model.logits, k=5)\n",
    "    batch_length = len(cnn_input)\n",
    "    feed_dict = {model.cnn_input: cnn_input, \n",
    "                 model.rnn_input: rnn_input,\n",
    "                 model.output_keep_prob: 1.0,\n",
    "                 model.batch_length:[batch_length],\n",
    "                 model.labels:y,\n",
    "                 model.tit_input_len:x_word_len_tit,\n",
    "                 model.des_input_len:x_word_len_des}\n",
    "    curr_eval_loss, predict_5 = sess.run([model.loss, predict_top_5], feed_dict)\n",
    "#     print (\"Evaluation loss:\",curr_eval_loss)\n",
    "#     print (\"real_labels:\",real_labels[:5])\n",
    "#     print (\"predict:\",predict_5[1][:5])\n",
    "#     print (\"predict:\",predict_5[0][:5])\n",
    "    predict_label_and_marked_label_list = []\n",
    "    for predict,label in zip(predict_5[1],real_labels):\n",
    "        predict_label_and_marked_label_list.append((list(predict),list(label)))\n",
    "    score = utils.eval(predict_label_and_marked_label_list)\n",
    "    return score, curr_eval_loss\n",
    "#     print(\"score:\",score)\n",
    "#     print \"--------------------Parting Line---------------------\"\n",
    "def save_best_model(score_list, step):\n",
    "    global max_score\n",
    "    avg_score = np.mean(score_list)\n",
    "    avg_score_str = \"%d steps avg score: %f\\n\" % (step, avg_score) \n",
    "    file_name = 'avg_loss_file'\n",
    "    save_path = './best_model/'\n",
    "    if os.path.exists(save_path):\n",
    "        wr = open(save_path + file_name, 'a')\n",
    "        wr.write(avg_score_str)\n",
    "        if avg_score > max_score:\n",
    "            max_score = avg_score\n",
    "            os.system('rm ./best_model/conv-rnn-model*')\n",
    "            os.system('cp ./models/conv-rnn-model-' + str(step) + '* ' + save_path)\n",
    "    else:\n",
    "        os.mkdir(save_path)\n",
    "        os.system('cp ./models/conv-rnn-model-' + str(step) + '* ' + save_path)   \n",
    "    print(avg_score_str)\n",
    "    print \"--------------------Parting Line---------------------\"\n",
    "    \n",
    "def predict(utils, restore=True):\n",
    "    with tf.Session() as sess:\n",
    "        if restore:\n",
    "            model = crnn.CRNN_char_word(cnn_seq_length, rnn_seq_length, batch_size, eval_batch_size, hidden_size, \n",
    "                                        lr, reg_rate, epoch_num, save_per_step, eval_per_step, keep_prob, \n",
    "                                        atn_hidden_size, shuffle, ckpt_path, num_sentences, \n",
    "                                        filter_sizes, num_filters, decay_steps, decay_rate, \n",
    "                                        vocab_size, char_size, embed_size, is_train)\n",
    "            model.saver.restore(sess=sess, save_path=tf.train.latest_checkpoint(ckpt_path))\n",
    "        predict_top_5 = tf.nn.top_k(model.logits, k=5)\n",
    "        pred_batches = utils.generate_p_batch()\n",
    "        for count, pred_batch in enumerate(pred_batches):\n",
    "            sys.stdout.write(\"Count %d\\r\" % count)\n",
    "            sys.stdout.flush()\n",
    "            x_char, x_word_tit, x_word_des, x_word_len_tit, x_word_len_des = zip(*(pred_batch))\n",
    "            x_pred_batch = np.concatenate((x_word_tit, x_word_des), axis=1)\n",
    "            batch_length = len(x_char)\n",
    "            feed_dict = {model.cnn_input: x_char, \n",
    "                         model.rnn_input: x_pred_batch,\n",
    "                         model.output_keep_prob: 1.0,\n",
    "                         model.batch_length:[batch_length],\n",
    "                         model.tit_input_len:x_word_len_tit,\n",
    "                         model.des_input_len:x_word_len_des}\n",
    "            predict_5 = sess.run(predict_top_5, feed_dict=feed_dict)\n",
    "            if count == 0:\n",
    "                predict = predict_5[1]\n",
    "            else:\n",
    "                predict = np.concatenate((predict,predict_5[1]))\n",
    "        np.savetxt(\"./Result/predict.txt\",predict,fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model checkpoint to models/conv-rnn-model-10500\n",
      "('Step:', 10500)\n",
      "('Train loss:', 0.0046422672)\n",
      "('avg eval loss:', 0.0043580793)\n",
      "10500 steps avg score: 0.373621\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-11000\n",
      "('Step:', 11000)\n",
      "('Train loss:', 0.0042656064)\n",
      "('avg eval loss:', 0.0044145593)\n",
      "11000 steps avg score: 0.371603\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-11500\n",
      "('Step:', 11500)\n",
      "('Train loss:', 0.0043622046)\n",
      "('avg eval loss:', 0.0044418448)\n",
      "11500 steps avg score: 0.372169\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-12000\n",
      "('Step:', 12000)\n",
      "('Train loss:', 0.0043260641)\n",
      "('avg eval loss:', 0.0043850178)\n",
      "12000 steps avg score: 0.372398\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-12500\n",
      "('Step:', 12500)\n",
      "('Train loss:', 0.0041980124)\n",
      "('avg eval loss:', 0.0043638595)\n",
      "12500 steps avg score: 0.373834\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-13000\n",
      "('Step:', 13000)\n",
      "('Train loss:', 0.0039212145)\n",
      "('avg eval loss:', 0.0043592565)\n",
      "13000 steps avg score: 0.377309\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-13500\n",
      "('Step:', 13500)\n",
      "('Train loss:', 0.0039162356)\n",
      "('avg eval loss:', 0.0043833433)\n",
      "13500 steps avg score: 0.375670\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-14000\n",
      "('Step:', 14000)\n",
      "('Train loss:', 0.0039989729)\n",
      "('avg eval loss:', 0.0043645976)\n",
      "14000 steps avg score: 0.376556\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-14500\n",
      "('Step:', 14500)\n",
      "('Train loss:', 0.0040855329)\n",
      "('avg eval loss:', 0.0043533174)\n",
      "14500 steps avg score: 0.378550\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-15000\n",
      "('Step:', 15000)\n",
      "('Train loss:', 0.0042411252)\n",
      "('avg eval loss:', 0.0043145451)\n",
      "15000 steps avg score: 0.379391\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-15500\n",
      "('Step:', 15500)\n",
      "('Train loss:', 0.0041369451)\n",
      "('avg eval loss:', 0.004285099)\n",
      "15500 steps avg score: 0.380835\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-16000\n",
      "('Step:', 16000)\n",
      "('Train loss:', 0.0042697424)\n",
      "('avg eval loss:', 0.0043460117)\n",
      "16000 steps avg score: 0.379310\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-16500\n",
      "('Step:', 16500)\n",
      "('Train loss:', 0.0043923976)\n",
      "('avg eval loss:', 0.0043672905)\n",
      "16500 steps avg score: 0.375009\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-17000\n",
      "('Step:', 17000)\n",
      "('Train loss:', 0.004319754)\n",
      "('avg eval loss:', 0.0043642614)\n",
      "17000 steps avg score: 0.377001\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-17500\n",
      "('Step:', 17500)\n",
      "('Train loss:', 0.0045678876)\n",
      "('avg eval loss:', 0.0043451833)\n",
      "17500 steps avg score: 0.376541\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-18000\n",
      "('Step:', 18000)\n",
      "('Train loss:', 0.0043670181)\n",
      "('avg eval loss:', 0.0043280749)\n",
      "18000 steps avg score: 0.380097\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-18500\n",
      "('Step:', 18500)\n",
      "('Train loss:', 0.0044535887)\n",
      "('avg eval loss:', 0.0043087793)\n",
      "18500 steps avg score: 0.379744\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-19000\n",
      "('Step:', 19000)\n",
      "('Train loss:', 0.0042838044)\n",
      "('avg eval loss:', 0.0042883703)\n",
      "19000 steps avg score: 0.382675\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-19500\n",
      "('Step:', 19500)\n",
      "('Train loss:', 0.0042288392)\n",
      "('avg eval loss:', 0.0042767418)\n",
      "19500 steps avg score: 0.382160\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-20000\n",
      "('Step:', 20000)\n",
      "('Train loss:', 0.0042503178)\n",
      "('avg eval loss:', 0.0042684479)\n",
      "20000 steps avg score: 0.381796\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-20500\n",
      "('Step:', 20500)\n",
      "('Train loss:', 0.0045519033)\n",
      "('avg eval loss:', 0.004292808)\n",
      "20500 steps avg score: 0.381518\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-21000\n",
      "('Step:', 21000)\n",
      "('Train loss:', 0.0043095509)\n",
      "('avg eval loss:', 0.0042480282)\n",
      "21000 steps avg score: 0.383117\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-21500\n",
      "('Step:', 21500)\n",
      "('Train loss:', 0.0043694223)\n",
      "('avg eval loss:', 0.0043058498)\n",
      "21500 steps avg score: 0.381738\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-22000\n",
      "('Step:', 22000)\n",
      "('Train loss:', 0.0040126028)\n",
      "('avg eval loss:', 0.0042721452)\n",
      "22000 steps avg score: 0.381578\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-22500\n",
      "('Step:', 22500)\n",
      "('Train loss:', 0.004030522)\n",
      "('avg eval loss:', 0.0043057851)\n",
      "22500 steps avg score: 0.382546\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-23000\n",
      "('Step:', 23000)\n",
      "('Train loss:', 0.0040127048)\n",
      "('avg eval loss:', 0.0042956946)\n",
      "23000 steps avg score: 0.381663\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-23500\n",
      "('Step:', 23500)\n",
      "('Train loss:', 0.0037558086)\n",
      "('avg eval loss:', 0.0042729499)\n",
      "23500 steps avg score: 0.381628\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-24000\n",
      "('Step:', 24000)\n",
      "('Train loss:', 0.0041165161)\n",
      "('avg eval loss:', 0.0042899665)\n",
      "24000 steps avg score: 0.381843\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-24500\n",
      "('Step:', 24500)\n",
      "('Train loss:', 0.0040301029)\n",
      "('avg eval loss:', 0.0042792549)\n",
      "24500 steps avg score: 0.384606\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-25000\n",
      "('Step:', 25000)\n",
      "('Train loss:', 0.0040454823)\n",
      "('avg eval loss:', 0.0042331782)\n",
      "25000 steps avg score: 0.385331\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-25500\n",
      "('Step:', 25500)\n",
      "('Train loss:', 0.0042423904)\n",
      "('avg eval loss:', 0.004271348)\n",
      "25500 steps avg score: 0.382687\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-26000\n",
      "('Step:', 26000)\n",
      "('Train loss:', 0.0037886824)\n",
      "('avg eval loss:', 0.0042456477)\n",
      "26000 steps avg score: 0.383452\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-26500\n",
      "('Step:', 26500)\n",
      "('Train loss:', 0.0041592792)\n",
      "('avg eval loss:', 0.0042757061)\n",
      "26500 steps avg score: 0.384537\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-27000\n",
      "('Step:', 27000)\n",
      "('Train loss:', 0.0041979351)\n",
      "('avg eval loss:', 0.0042593135)\n",
      "27000 steps avg score: 0.383941\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-27500\n",
      "('Step:', 27500)\n",
      "('Train loss:', 0.0037261541)\n",
      "('avg eval loss:', 0.0042666183)\n",
      "27500 steps avg score: 0.384162\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-28000\n",
      "('Step:', 28000)\n",
      "('Train loss:', 0.0040555759)\n",
      "('avg eval loss:', 0.0042530587)\n",
      "28000 steps avg score: 0.383775\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-28500\n",
      "('Step:', 28500)\n",
      "('Train loss:', 0.0040244623)\n",
      "('avg eval loss:', 0.0042534126)\n",
      "28500 steps avg score: 0.385474\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-29000\n",
      "('Step:', 29000)\n",
      "('Train loss:', 0.0040817261)\n",
      "('avg eval loss:', 0.0042376015)\n",
      "29000 steps avg score: 0.385668\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-29500\n",
      "('Step:', 29500)\n",
      "('Train loss:', 0.0042309561)\n",
      "('avg eval loss:', 0.004257876)\n",
      "29500 steps avg score: 0.387003\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-30000\n",
      "('Step:', 30000)\n",
      "('Train loss:', 0.0038181222)\n",
      "('avg eval loss:', 0.0042271549)\n",
      "30000 steps avg score: 0.385886\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-30500\n",
      "('Step:', 30500)\n",
      "('Train loss:', 0.0042425119)\n",
      "('avg eval loss:', 0.0042321975)\n",
      "30500 steps avg score: 0.387220\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-31000\n",
      "('Step:', 31000)\n",
      "('Train loss:', 0.003985073)\n",
      "('avg eval loss:', 0.0041894731)\n",
      "31000 steps avg score: 0.389355\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-31500\n",
      "('Step:', 31500)\n",
      "('Train loss:', 0.0037400385)\n",
      "('avg eval loss:', 0.0042233104)\n",
      "31500 steps avg score: 0.386330\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-32000\n",
      "('Step:', 32000)\n",
      "('Train loss:', 0.0039852746)\n",
      "('avg eval loss:', 0.0042558732)\n",
      "32000 steps avg score: 0.386577\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-32500\n",
      "('Step:', 32500)\n",
      "('Train loss:', 0.003990449)\n",
      "('avg eval loss:', 0.0042656576)\n",
      "32500 steps avg score: 0.386199\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-33000\n",
      "('Step:', 33000)\n",
      "('Train loss:', 0.003866093)\n",
      "('avg eval loss:', 0.0042233393)\n",
      "33000 steps avg score: 0.389440\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-33500\n",
      "('Step:', 33500)\n",
      "('Train loss:', 0.0038479217)\n",
      "('avg eval loss:', 0.0042422949)\n",
      "33500 steps avg score: 0.388048\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-34000\n",
      "('Step:', 34000)\n",
      "('Train loss:', 0.0039786748)\n",
      "('avg eval loss:', 0.0042513297)\n",
      "34000 steps avg score: 0.384502\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-34500\n",
      "('Step:', 34500)\n",
      "('Train loss:', 0.0041027907)\n",
      "('avg eval loss:', 0.0042601163)\n",
      "34500 steps avg score: 0.387029\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-35000\n",
      "('Step:', 35000)\n",
      "('Train loss:', 0.0037330149)\n",
      "('avg eval loss:', 0.004259719)\n",
      "35000 steps avg score: 0.386429\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-35500\n",
      "('Step:', 35500)\n",
      "('Train loss:', 0.0039472361)\n",
      "('avg eval loss:', 0.0042560911)\n",
      "35500 steps avg score: 0.387729\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-36000\n",
      "('Step:', 36000)\n",
      "('Train loss:', 0.0036340202)\n",
      "('avg eval loss:', 0.0042513134)\n",
      "36000 steps avg score: 0.386770\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-36500\n",
      "('Step:', 36500)\n",
      "('Train loss:', 0.0040210527)\n",
      "('avg eval loss:', 0.0042650262)\n",
      "36500 steps avg score: 0.385046\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-37000\n",
      "('Step:', 37000)\n",
      "('Train loss:', 0.0037942813)\n",
      "('avg eval loss:', 0.0042279814)\n",
      "37000 steps avg score: 0.388301\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-37500\n",
      "('Step:', 37500)\n",
      "('Train loss:', 0.0037200148)\n",
      "('avg eval loss:', 0.0042329067)\n",
      "37500 steps avg score: 0.387405\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-38000\n",
      "('Step:', 38000)\n",
      "('Train loss:', 0.0036484364)\n",
      "('avg eval loss:', 0.0042654895)\n",
      "38000 steps avg score: 0.386454\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-38500\n",
      "('Step:', 38500)\n",
      "('Train loss:', 0.0040049898)\n",
      "('avg eval loss:', 0.0042195222)\n",
      "38500 steps avg score: 0.388857\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-39000\n",
      "('Step:', 39000)\n",
      "('Train loss:', 0.0033950051)\n",
      "('avg eval loss:', 0.004211056)\n",
      "39000 steps avg score: 0.390598\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-39500\n",
      "('Step:', 39500)\n",
      "('Train loss:', 0.0041978327)\n",
      "('avg eval loss:', 0.0042735422)\n",
      "39500 steps avg score: 0.386127\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-40000\n",
      "('Step:', 40000)\n",
      "('Train loss:', 0.0038391908)\n",
      "('avg eval loss:', 0.0042335549)\n",
      "40000 steps avg score: 0.387043\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-40500\n",
      "('Step:', 40500)\n",
      "('Train loss:', 0.0040796115)\n",
      "('avg eval loss:', 0.0041904976)\n",
      "40500 steps avg score: 0.391178\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-41000\n",
      "('Step:', 41000)\n",
      "('Train loss:', 0.0038931463)\n",
      "('avg eval loss:', 0.0042306986)\n",
      "41000 steps avg score: 0.388541\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-41500\n",
      "('Step:', 41500)\n",
      "('Train loss:', 0.0041585974)\n",
      "('avg eval loss:', 0.0042296862)\n",
      "41500 steps avg score: 0.387179\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-42000\n",
      "('Step:', 42000)\n",
      "('Train loss:', 0.0036697893)\n",
      "('avg eval loss:', 0.0042358022)\n",
      "42000 steps avg score: 0.387349\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-42500\n",
      "('Step:', 42500)\n",
      "('Train loss:', 0.0035878862)\n",
      "('avg eval loss:', 0.0042573074)\n",
      "42500 steps avg score: 0.387407\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-43000\n",
      "('Step:', 43000)\n",
      "('Train loss:', 0.0038331712)\n",
      "('avg eval loss:', 0.0042714211)\n",
      "43000 steps avg score: 0.388453\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-43500\n",
      "('Step:', 43500)\n",
      "('Train loss:', 0.003940925)\n",
      "('avg eval loss:', 0.0042650304)\n",
      "43500 steps avg score: 0.386679\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-44000\n",
      "('Step:', 44000)\n",
      "('Train loss:', 0.0042080986)\n",
      "('avg eval loss:', 0.0042657717)\n",
      "44000 steps avg score: 0.386269\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-44500\n",
      "('Step:', 44500)\n",
      "('Train loss:', 0.0039010341)\n",
      "('avg eval loss:', 0.004246912)\n",
      "44500 steps avg score: 0.389178\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-45000\n",
      "('Step:', 45000)\n",
      "('Train loss:', 0.0035976493)\n",
      "('avg eval loss:', 0.0042956541)\n",
      "45000 steps avg score: 0.384544\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-45500\n",
      "('Step:', 45500)\n",
      "('Train loss:', 0.003645051)\n",
      "('avg eval loss:', 0.0042481436)\n",
      "45500 steps avg score: 0.388285\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-46000\n",
      "('Step:', 46000)\n",
      "('Train loss:', 0.0039233174)\n",
      "('avg eval loss:', 0.004241908)\n",
      "46000 steps avg score: 0.390069\n",
      "\n",
      "--------------------Parting Line---------------------\n",
      "Saved model checkpoint to models/conv-rnn-model-46500\n",
      "('Step:', 46500)\n",
      "('Train loss:', 0.0039843195)\n",
      "('avg eval loss:', 0.0042577153)\n",
      "46500 steps avg score: 0.387099\n",
      "\n",
      "--------------------Parting Line---------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9ad522bf94b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-3cc7291b8241>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(sess, utils)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         train_loss, step, summary, _= sess.run([model.loss, model.global_step, model.merged, model.train_op], \n\u001b[0;32m---> 28\u001b[0;31m                                                 feed_dict) \n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0meval_per_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jasperyang/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    train(sess, utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params conf. file store success!\n",
      "INFO:tensorflow:Restoring parameters from ./models/conv-rnn-model-46500\n",
      "('predict_set_num_batches:', 109)\n",
      "Count 108\r"
     ]
    }
   ],
   "source": [
    "print(\"params conf. file store success!\")\n",
    "predict(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = utils.generate_p_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('predict_set_num_batches:', 725)\n"
     ]
    }
   ],
   "source": [
    "a,b,c,d,e = zip(*(pred.next()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
